{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torchvision import models\n",
    "import torchinfo\n",
    "from torchvision import transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BuildingBlock(nn.Module):\n",
    "    def __init__(self, in_feats: int, out_feats: int, first_stride=1):\n",
    "        super().__init__()\n",
    "        self.left = nn.Sequential(\n",
    "            nn.Conv2d(in_feats, out_feats, kernel_size=3, stride=first_stride, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_feats),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_feats, out_feats, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_feats)\n",
    "        )\n",
    "\n",
    "        if first_stride > 1:\n",
    "            self.right = nn.Sequential(\n",
    "                nn.Conv2d(in_feats, out_feats, kernel_size=1, stride=first_stride, padding=0, bias=False),\n",
    "                nn.BatchNorm2d(out_feats)\n",
    "            )\n",
    "        else:\n",
    "            self.right = nn.Sequential( # Redundant, but for consistency\n",
    "                nn.Identity()\n",
    "            )\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        left_out = self.left(x)\n",
    "        right_out = self.right(x)\n",
    "        print(left_out.shape, right_out.shape)\n",
    "        return F.relu(left_out + right_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Group(nn.Module):\n",
    "    def __init__(self, n_blocks: int, in_feats: int, out_feats: int, first_stride=1):\n",
    "        super().__init__()\n",
    "        self.blocks = nn.Sequential(\n",
    "            BuildingBlock(in_feats, out_feats, first_stride),\n",
    "            *[BuildingBlock(out_feats, out_feats) for _ in range(n_blocks - 1)]\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.blocks(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet34(nn.Module):\n",
    "    def __init__(self, groupSizes=[3, 4, 6, 3], groupFeats=[64, 128, 256, 512], groupFirstStrides=[1, 2, 2, 2], num_classes=1000):\n",
    "        super().__init__()\n",
    "        inGroupFeats = [groupFeats[0]] + groupFeats[:-1]\n",
    "        print(inGroupFeats)\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(3, groupFeats[0], 7, 2, 3, bias=False),\n",
    "            nn.BatchNorm2d(groupFeats[0]),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(3, 2, 1),\n",
    "            *[Group(groupSizes[i], inGroupFeats[i], groupFeats[i], groupFirstStrides[i]) for i in range(len(groupSizes))],\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(groupFeats[-1], num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[64, 64, 128, 256]\n",
      "torch.Size([1, 64, 56, 56]) torch.Size([1, 64, 56, 56])\n",
      "torch.Size([1, 64, 56, 56]) torch.Size([1, 64, 56, 56])\n",
      "torch.Size([1, 64, 56, 56]) torch.Size([1, 64, 56, 56])\n",
      "torch.Size([1, 128, 28, 28]) torch.Size([1, 128, 28, 28])\n",
      "torch.Size([1, 128, 28, 28]) torch.Size([1, 128, 28, 28])\n",
      "torch.Size([1, 128, 28, 28]) torch.Size([1, 128, 28, 28])\n",
      "torch.Size([1, 128, 28, 28]) torch.Size([1, 128, 28, 28])\n",
      "torch.Size([1, 256, 14, 14]) torch.Size([1, 256, 14, 14])\n",
      "torch.Size([1, 256, 14, 14]) torch.Size([1, 256, 14, 14])\n",
      "torch.Size([1, 256, 14, 14]) torch.Size([1, 256, 14, 14])\n",
      "torch.Size([1, 256, 14, 14]) torch.Size([1, 256, 14, 14])\n",
      "torch.Size([1, 256, 14, 14]) torch.Size([1, 256, 14, 14])\n",
      "torch.Size([1, 256, 14, 14]) torch.Size([1, 256, 14, 14])\n",
      "torch.Size([1, 512, 7, 7]) torch.Size([1, 512, 7, 7])\n",
      "torch.Size([1, 512, 7, 7]) torch.Size([1, 512, 7, 7])\n",
      "torch.Size([1, 512, 7, 7]) torch.Size([1, 512, 7, 7])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1000])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = ResNet34()\n",
    "temp(torch.randn(1, 3, 224, 224)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "ResNet                                   [1, 1000]                 --\n",
      "├─Conv2d: 1-1                            [1, 64, 32, 32]           9,408\n",
      "├─BatchNorm2d: 1-2                       [1, 64, 32, 32]           128\n",
      "├─ReLU: 1-3                              [1, 64, 32, 32]           --\n",
      "├─MaxPool2d: 1-4                         [1, 64, 16, 16]           --\n",
      "├─Sequential: 1-5                        [1, 64, 16, 16]           --\n",
      "│    └─BasicBlock: 2-1                   [1, 64, 16, 16]           --\n",
      "│    │    └─Conv2d: 3-1                  [1, 64, 16, 16]           36,864\n",
      "│    │    └─BatchNorm2d: 3-2             [1, 64, 16, 16]           128\n",
      "│    │    └─ReLU: 3-3                    [1, 64, 16, 16]           --\n",
      "│    │    └─Conv2d: 3-4                  [1, 64, 16, 16]           36,864\n",
      "│    │    └─BatchNorm2d: 3-5             [1, 64, 16, 16]           128\n",
      "│    │    └─ReLU: 3-6                    [1, 64, 16, 16]           --\n",
      "│    └─BasicBlock: 2-2                   [1, 64, 16, 16]           --\n",
      "│    │    └─Conv2d: 3-7                  [1, 64, 16, 16]           36,864\n",
      "│    │    └─BatchNorm2d: 3-8             [1, 64, 16, 16]           128\n",
      "│    │    └─ReLU: 3-9                    [1, 64, 16, 16]           --\n",
      "│    │    └─Conv2d: 3-10                 [1, 64, 16, 16]           36,864\n",
      "│    │    └─BatchNorm2d: 3-11            [1, 64, 16, 16]           128\n",
      "│    │    └─ReLU: 3-12                   [1, 64, 16, 16]           --\n",
      "│    └─BasicBlock: 2-3                   [1, 64, 16, 16]           --\n",
      "│    │    └─Conv2d: 3-13                 [1, 64, 16, 16]           36,864\n",
      "│    │    └─BatchNorm2d: 3-14            [1, 64, 16, 16]           128\n",
      "│    │    └─ReLU: 3-15                   [1, 64, 16, 16]           --\n",
      "│    │    └─Conv2d: 3-16                 [1, 64, 16, 16]           36,864\n",
      "│    │    └─BatchNorm2d: 3-17            [1, 64, 16, 16]           128\n",
      "│    │    └─ReLU: 3-18                   [1, 64, 16, 16]           --\n",
      "├─Sequential: 1-6                        [1, 128, 8, 8]            --\n",
      "│    └─BasicBlock: 2-4                   [1, 128, 8, 8]            --\n",
      "│    │    └─Conv2d: 3-19                 [1, 128, 8, 8]            73,728\n",
      "│    │    └─BatchNorm2d: 3-20            [1, 128, 8, 8]            256\n",
      "│    │    └─ReLU: 3-21                   [1, 128, 8, 8]            --\n",
      "│    │    └─Conv2d: 3-22                 [1, 128, 8, 8]            147,456\n",
      "│    │    └─BatchNorm2d: 3-23            [1, 128, 8, 8]            256\n",
      "│    │    └─Sequential: 3-24             [1, 128, 8, 8]            8,448\n",
      "│    │    └─ReLU: 3-25                   [1, 128, 8, 8]            --\n",
      "│    └─BasicBlock: 2-5                   [1, 128, 8, 8]            --\n",
      "│    │    └─Conv2d: 3-26                 [1, 128, 8, 8]            147,456\n",
      "│    │    └─BatchNorm2d: 3-27            [1, 128, 8, 8]            256\n",
      "│    │    └─ReLU: 3-28                   [1, 128, 8, 8]            --\n",
      "│    │    └─Conv2d: 3-29                 [1, 128, 8, 8]            147,456\n",
      "│    │    └─BatchNorm2d: 3-30            [1, 128, 8, 8]            256\n",
      "│    │    └─ReLU: 3-31                   [1, 128, 8, 8]            --\n",
      "│    └─BasicBlock: 2-6                   [1, 128, 8, 8]            --\n",
      "│    │    └─Conv2d: 3-32                 [1, 128, 8, 8]            147,456\n",
      "│    │    └─BatchNorm2d: 3-33            [1, 128, 8, 8]            256\n",
      "│    │    └─ReLU: 3-34                   [1, 128, 8, 8]            --\n",
      "│    │    └─Conv2d: 3-35                 [1, 128, 8, 8]            147,456\n",
      "│    │    └─BatchNorm2d: 3-36            [1, 128, 8, 8]            256\n",
      "│    │    └─ReLU: 3-37                   [1, 128, 8, 8]            --\n",
      "│    └─BasicBlock: 2-7                   [1, 128, 8, 8]            --\n",
      "│    │    └─Conv2d: 3-38                 [1, 128, 8, 8]            147,456\n",
      "│    │    └─BatchNorm2d: 3-39            [1, 128, 8, 8]            256\n",
      "│    │    └─ReLU: 3-40                   [1, 128, 8, 8]            --\n",
      "│    │    └─Conv2d: 3-41                 [1, 128, 8, 8]            147,456\n",
      "│    │    └─BatchNorm2d: 3-42            [1, 128, 8, 8]            256\n",
      "│    │    └─ReLU: 3-43                   [1, 128, 8, 8]            --\n",
      "├─Sequential: 1-7                        [1, 256, 4, 4]            --\n",
      "│    └─BasicBlock: 2-8                   [1, 256, 4, 4]            --\n",
      "│    │    └─Conv2d: 3-44                 [1, 256, 4, 4]            294,912\n",
      "│    │    └─BatchNorm2d: 3-45            [1, 256, 4, 4]            512\n",
      "│    │    └─ReLU: 3-46                   [1, 256, 4, 4]            --\n",
      "│    │    └─Conv2d: 3-47                 [1, 256, 4, 4]            589,824\n",
      "│    │    └─BatchNorm2d: 3-48            [1, 256, 4, 4]            512\n",
      "│    │    └─Sequential: 3-49             [1, 256, 4, 4]            33,280\n",
      "│    │    └─ReLU: 3-50                   [1, 256, 4, 4]            --\n",
      "│    └─BasicBlock: 2-9                   [1, 256, 4, 4]            --\n",
      "│    │    └─Conv2d: 3-51                 [1, 256, 4, 4]            589,824\n",
      "│    │    └─BatchNorm2d: 3-52            [1, 256, 4, 4]            512\n",
      "│    │    └─ReLU: 3-53                   [1, 256, 4, 4]            --\n",
      "│    │    └─Conv2d: 3-54                 [1, 256, 4, 4]            589,824\n",
      "│    │    └─BatchNorm2d: 3-55            [1, 256, 4, 4]            512\n",
      "│    │    └─ReLU: 3-56                   [1, 256, 4, 4]            --\n",
      "│    └─BasicBlock: 2-10                  [1, 256, 4, 4]            --\n",
      "│    │    └─Conv2d: 3-57                 [1, 256, 4, 4]            589,824\n",
      "│    │    └─BatchNorm2d: 3-58            [1, 256, 4, 4]            512\n",
      "│    │    └─ReLU: 3-59                   [1, 256, 4, 4]            --\n",
      "│    │    └─Conv2d: 3-60                 [1, 256, 4, 4]            589,824\n",
      "│    │    └─BatchNorm2d: 3-61            [1, 256, 4, 4]            512\n",
      "│    │    └─ReLU: 3-62                   [1, 256, 4, 4]            --\n",
      "│    └─BasicBlock: 2-11                  [1, 256, 4, 4]            --\n",
      "│    │    └─Conv2d: 3-63                 [1, 256, 4, 4]            589,824\n",
      "│    │    └─BatchNorm2d: 3-64            [1, 256, 4, 4]            512\n",
      "│    │    └─ReLU: 3-65                   [1, 256, 4, 4]            --\n",
      "│    │    └─Conv2d: 3-66                 [1, 256, 4, 4]            589,824\n",
      "│    │    └─BatchNorm2d: 3-67            [1, 256, 4, 4]            512\n",
      "│    │    └─ReLU: 3-68                   [1, 256, 4, 4]            --\n",
      "│    └─BasicBlock: 2-12                  [1, 256, 4, 4]            --\n",
      "│    │    └─Conv2d: 3-69                 [1, 256, 4, 4]            589,824\n",
      "│    │    └─BatchNorm2d: 3-70            [1, 256, 4, 4]            512\n",
      "│    │    └─ReLU: 3-71                   [1, 256, 4, 4]            --\n",
      "│    │    └─Conv2d: 3-72                 [1, 256, 4, 4]            589,824\n",
      "│    │    └─BatchNorm2d: 3-73            [1, 256, 4, 4]            512\n",
      "│    │    └─ReLU: 3-74                   [1, 256, 4, 4]            --\n",
      "│    └─BasicBlock: 2-13                  [1, 256, 4, 4]            --\n",
      "│    │    └─Conv2d: 3-75                 [1, 256, 4, 4]            589,824\n",
      "│    │    └─BatchNorm2d: 3-76            [1, 256, 4, 4]            512\n",
      "│    │    └─ReLU: 3-77                   [1, 256, 4, 4]            --\n",
      "│    │    └─Conv2d: 3-78                 [1, 256, 4, 4]            589,824\n",
      "│    │    └─BatchNorm2d: 3-79            [1, 256, 4, 4]            512\n",
      "│    │    └─ReLU: 3-80                   [1, 256, 4, 4]            --\n",
      "├─Sequential: 1-8                        [1, 512, 2, 2]            --\n",
      "│    └─BasicBlock: 2-14                  [1, 512, 2, 2]            --\n",
      "│    │    └─Conv2d: 3-81                 [1, 512, 2, 2]            1,179,648\n",
      "│    │    └─BatchNorm2d: 3-82            [1, 512, 2, 2]            1,024\n",
      "│    │    └─ReLU: 3-83                   [1, 512, 2, 2]            --\n",
      "│    │    └─Conv2d: 3-84                 [1, 512, 2, 2]            2,359,296\n",
      "│    │    └─BatchNorm2d: 3-85            [1, 512, 2, 2]            1,024\n",
      "│    │    └─Sequential: 3-86             [1, 512, 2, 2]            132,096\n",
      "│    │    └─ReLU: 3-87                   [1, 512, 2, 2]            --\n",
      "│    └─BasicBlock: 2-15                  [1, 512, 2, 2]            --\n",
      "│    │    └─Conv2d: 3-88                 [1, 512, 2, 2]            2,359,296\n",
      "│    │    └─BatchNorm2d: 3-89            [1, 512, 2, 2]            1,024\n",
      "│    │    └─ReLU: 3-90                   [1, 512, 2, 2]            --\n",
      "│    │    └─Conv2d: 3-91                 [1, 512, 2, 2]            2,359,296\n",
      "│    │    └─BatchNorm2d: 3-92            [1, 512, 2, 2]            1,024\n",
      "│    │    └─ReLU: 3-93                   [1, 512, 2, 2]            --\n",
      "│    └─BasicBlock: 2-16                  [1, 512, 2, 2]            --\n",
      "│    │    └─Conv2d: 3-94                 [1, 512, 2, 2]            2,359,296\n",
      "│    │    └─BatchNorm2d: 3-95            [1, 512, 2, 2]            1,024\n",
      "│    │    └─ReLU: 3-96                   [1, 512, 2, 2]            --\n",
      "│    │    └─Conv2d: 3-97                 [1, 512, 2, 2]            2,359,296\n",
      "│    │    └─BatchNorm2d: 3-98            [1, 512, 2, 2]            1,024\n",
      "│    │    └─ReLU: 3-99                   [1, 512, 2, 2]            --\n",
      "├─AdaptiveAvgPool2d: 1-9                 [1, 512, 1, 1]            --\n",
      "├─Linear: 1-10                           [1, 1000]                 513,000\n",
      "==========================================================================================\n",
      "Total params: 21,797,672\n",
      "Trainable params: 21,797,672\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 299.57\n",
      "==========================================================================================\n",
      "Input size (MB): 0.05\n",
      "Forward/backward pass size (MB): 4.89\n",
      "Params size (MB): 87.19\n",
      "Estimated Total Size (MB): 92.13\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "resnet = models.resnet34()\n",
    "print(torchinfo.summary(resnet, input_size=(1, 3, 64, 64)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[64, 64, 128, 256]\n"
     ]
    }
   ],
   "source": [
    "def copy_weights(myresnet, pretrained_resnet):\n",
    "    mydict = myresnet.state_dict()\n",
    "    pretraineddict = pretrained_resnet.state_dict()\n",
    "    state_dict_to_load = {\n",
    "        mykey: pretrainedvalue\n",
    "        for (mykey, _), (_, pretrainedvalue) in zip(mydict.items(), pretraineddict.items())\n",
    "    }\n",
    "\n",
    "    myresnet.load_state_dict(state_dict_to_load)\n",
    "\n",
    "    return myresnet\n",
    "\n",
    "\n",
    "pretrained_resnet = models.resnet34(weights=models.ResNet34_Weights.IMAGENET1K_V1)\n",
    "myresnet = ResNet34()\n",
    "myresnet = copy_weights(myresnet, pretrained_resnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"model.pth\"\n",
    "torch.save(myresnet.state_dict(), save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/manandaga/miniforge3/envs/dl-course/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "astro = Image.open('astro.jpg')\n",
    "IMAGE_SIZE = 224\n",
    "IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
    "IMAGENET_STD = [0.229, 0.224, 0.225]\n",
    "\n",
    "IMAGENET_TRANSFORM = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "    transforms.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
    "])\n",
    "\n",
    "prepared_image = IMAGENET_TRANSFORM(astro).unsqueeze(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "570 gas mask\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "pretrained_resnet.eval()\n",
    "LABELS_URL = \"https://raw.githubusercontent.com/anishathalye/imagenet-simple-labels/master/imagenet-simple-labels.json\"\n",
    "labels = requests.get(LABELS_URL).json()\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = pretrained_resnet(prepared_image)\n",
    "    print(output.argmax().item(), labels[output.argmax().item()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl-course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
